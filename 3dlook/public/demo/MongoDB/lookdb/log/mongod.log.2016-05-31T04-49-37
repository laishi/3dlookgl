2016-05-23T17:41:45.539+0800 I CONTROL  [initandlisten] MongoDB starting : pid=8676 port=3523 dbpath=/home/laishi/APP/MongoDB/lookdb/data 64-bit host=fedora
2016-05-23T17:41:45.539+0800 I CONTROL  [initandlisten] db version v3.2.6
2016-05-23T17:41:45.539+0800 I CONTROL  [initandlisten] git version: 05552b562c7a0b3143a729aaa0838e558dc49b25
2016-05-23T17:41:45.539+0800 I CONTROL  [initandlisten] OpenSSL version: OpenSSL 1.0.1e-fips 11 Feb 2013
2016-05-23T17:41:45.539+0800 I CONTROL  [initandlisten] allocator: tcmalloc
2016-05-23T17:41:45.539+0800 I CONTROL  [initandlisten] modules: none
2016-05-23T17:41:45.539+0800 I CONTROL  [initandlisten] build environment:
2016-05-23T17:41:45.539+0800 I CONTROL  [initandlisten]     distmod: rhel70
2016-05-23T17:41:45.539+0800 I CONTROL  [initandlisten]     distarch: x86_64
2016-05-23T17:41:45.539+0800 I CONTROL  [initandlisten]     target_arch: x86_64
2016-05-23T17:41:45.539+0800 I CONTROL  [initandlisten] options: { config: "./conf/mongod.conf", net: { port: 3523 }, processManagement: { fork: true }, storage: { dbPath: "data" }, systemLog: { destination: "file", path: "log/mongod.log" } }
2016-05-23T17:41:45.558+0800 I -        [initandlisten] Detected data files in /home/laishi/APP/MongoDB/lookdb/data created by the 'wiredTiger' storage engine, so setting the active storage engine to 'wiredTiger'.
2016-05-23T17:41:45.558+0800 I STORAGE  [initandlisten] wiredtiger_open config: create,cache_size=1G,session_max=20000,eviction=(threads_max=4),config_base=false,statistics=(fast),log=(enabled=true,archive=true,path=journal,compressor=snappy),file_manager=(close_idle_time=100000),checkpoint=(wait=60,log_size=2GB),statistics_log=(wait=0),
2016-05-23T17:41:46.933+0800 I CONTROL  [initandlisten] 
2016-05-23T17:41:46.933+0800 I CONTROL  [initandlisten] ** WARNING: /sys/kernel/mm/transparent_hugepage/defrag is 'always'.
2016-05-23T17:41:46.933+0800 I CONTROL  [initandlisten] **        We suggest setting it to 'never'
2016-05-23T17:41:46.933+0800 I CONTROL  [initandlisten] 
2016-05-23T17:41:46.935+0800 I FTDC     [initandlisten] Initializing full-time diagnostic data capture with directory '/home/laishi/APP/MongoDB/lookdb/data/diagnostic.data'
2016-05-23T17:41:46.935+0800 I NETWORK  [HostnameCanonicalizationWorker] Starting hostname canonicalization worker
2016-05-23T17:41:46.936+0800 I NETWORK  [initandlisten] waiting for connections on port 3523
2016-05-23T17:44:59.337+0800 I NETWORK  [initandlisten] connection accepted from 127.0.0.1:41650 #1 (1 connection now open)
2016-05-23T17:50:04.927+0800 I COMMAND  [conn1] command lookuser.users command: insert { insert: "users", documents: [ { _id: ObjectId('5742d24cf9e821bf07d4bc9c'), name: "laishi" } ], ordered: true } ninserted:1 keyUpdates:0 writeConflicts:0 numYields:0 reslen:25 locks:{ Global: { acquireCount: { r: 2, w: 2 } }, Database: { acquireCount: { w: 1, W: 1 } }, Collection: { acquireCount: { W: 1 } } } protocol:op_command 134ms
2016-05-23T18:33:20.092+0800 I NETWORK  [initandlisten] connection accepted from 127.0.0.1:37266 #2 (2 connections now open)
2016-05-23T18:33:20.327+0800 I COMMAND  [conn2] command lookuser.books command: insert { insert: "books", documents: [ { name: "yi yong ren ti", author: "laishi", _id: ObjectId('5742dc70dc5ca71128f71818'), __v: 0 } ], ordered: false, writeConcern: { w: 1 } } ninserted:1 keyUpdates:0 writeConflicts:0 numYields:0 reslen:40 locks:{ Global: { acquireCount: { r: 2, w: 2 } }, Database: { acquireCount: { w: 1, W: 1 } }, Collection: { acquireCount: { w: 1, W: 1 } } } protocol:op_query 218ms
2016-05-23T18:34:19.042+0800 I NETWORK  [conn2] end connection 127.0.0.1:37266 (1 connection now open)
2016-05-23T18:35:46.472+0800 I NETWORK  [initandlisten] connection accepted from 127.0.0.1:39886 #3 (2 connections now open)
2016-05-23T18:37:46.833+0800 I NETWORK  [conn3] end connection 127.0.0.1:39886 (1 connection now open)
2016-05-23T18:37:49.899+0800 I NETWORK  [initandlisten] connection accepted from 127.0.0.1:42072 #4 (2 connections now open)
2016-05-23T18:37:50.279+0800 I COMMAND  [conn4] command book.books command: insert { insert: "books", documents: [ { name: "yi yong ren ti", author: "laishi", _id: ObjectId('5742dd7dcc65ebaf28a7cbbe'), __v: 0 } ], ordered: false, writeConcern: { w: 1 } } ninserted:1 keyUpdates:0 writeConflicts:0 numYields:0 reslen:40 locks:{ Global: { acquireCount: { r: 2, w: 2 } }, Database: { acquireCount: { w: 1, W: 1 } }, Collection: { acquireCount: { W: 1 } } } protocol:op_query 362ms
2016-05-23T18:48:20.192+0800 I NETWORK  [conn4] end connection 127.0.0.1:42072 (1 connection now open)
2016-05-23T18:48:50.565+0800 I NETWORK  [initandlisten] connection accepted from 127.0.0.1:53888 #5 (2 connections now open)
2016-05-23T18:50:21.883+0800 I NETWORK  [conn5] end connection 127.0.0.1:53888 (1 connection now open)
2016-05-23T18:50:26.473+0800 I NETWORK  [initandlisten] connection accepted from 127.0.0.1:55686 #6 (2 connections now open)
2016-05-23T18:50:29.171+0800 I NETWORK  [conn6] end connection 127.0.0.1:55686 (1 connection now open)
2016-05-23T18:50:32.413+0800 I NETWORK  [initandlisten] connection accepted from 127.0.0.1:55788 #7 (2 connections now open)
2016-05-23T18:51:21.172+0800 I NETWORK  [conn7] end connection 127.0.0.1:55788 (1 connection now open)
2016-05-23T18:51:25.607+0800 I NETWORK  [initandlisten] connection accepted from 127.0.0.1:56744 #8 (2 connections now open)
2016-05-23T18:51:28.026+0800 I NETWORK  [conn8] end connection 127.0.0.1:56744 (1 connection now open)
2016-05-23T18:51:31.217+0800 I NETWORK  [initandlisten] connection accepted from 127.0.0.1:56842 #9 (2 connections now open)
2016-05-23T19:52:48.397+0800 I NETWORK  [conn1] end connection 127.0.0.1:41650 (1 connection now open)
2016-05-23T19:52:55.085+0800 I NETWORK  [conn9] end connection 127.0.0.1:56842 (0 connections now open)
2016-05-23T21:19:48.426+0800 I COMMAND  [PeriodicTaskRunner] task: DBConnectionPool-cleaner took: 190ms
2016-05-23T21:34:50.399+0800 I COMMAND  [PeriodicTaskRunner] task: DBConnectionPool-cleaner took: 244ms
2016-05-23T21:34:51.634+0800 I COMMAND  [PeriodicTaskRunner] task: UnusedLockCleaner took: 139ms
2016-05-24T06:01:25.181+0800 I COMMAND  [PeriodicTaskRunner] task: DBConnectionPool-cleaner took: 1643ms
2016-05-24T06:01:38.691+0800 I COMMAND  [ftdc] serverStatus was very slow: { after basic: 0, after asserts: 0, after connections: 0, after extra_info: 1460, after globalLock: 1460, after locks: 1460, after network: 1460, after opcounters: 1460, after opcountersRepl: 1460, after storageEngine: 1460, after tcmalloc: 1460, after wiredTiger: 1460, at end: 1460 }
2016-05-24T06:02:26.500+0800 I COMMAND  [PeriodicTaskRunner] task: DBConnectionPool-cleaner took: 575ms
2016-05-24T13:30:14.865+0800 I COMMAND  [ftdc] serverStatus was very slow: { after basic: 0, after asserts: 0, after connections: 0, after extra_info: 1770, after globalLock: 1770, after locks: 1770, after network: 1770, after opcounters: 1770, after opcountersRepl: 1770, after storageEngine: 1770, after tcmalloc: 1770, after wiredTiger: 1770, at end: 1770 }
2016-05-24T13:31:35.753+0800 I COMMAND  [ftdc] serverStatus was very slow: { after basic: 0, after asserts: 0, after connections: 0, after extra_info: 1680, after globalLock: 1680, after locks: 1680, after network: 1680, after opcounters: 1680, after opcountersRepl: 1680, after storageEngine: 1680, after tcmalloc: 1680, after wiredTiger: 1680, at end: 1680 }
2016-05-24T13:32:42.991+0800 I COMMAND  [ftdc] serverStatus was very slow: { after basic: 0, after asserts: 0, after connections: 0, after extra_info: 1980, after globalLock: 1980, after locks: 1980, after network: 1980, after opcounters: 1980, after opcountersRepl: 1980, after storageEngine: 1980, after tcmalloc: 1980, after wiredTiger: 1980, at end: 1980 }
2016-05-24T13:33:02.116+0800 I COMMAND  [ftdc] serverStatus was very slow: { after basic: 0, after asserts: 0, after connections: 0, after extra_info: 4090, after globalLock: 4090, after locks: 4090, after network: 4090, after opcounters: 4090, after opcountersRepl: 4090, after storageEngine: 4090, after tcmalloc: 4090, after wiredTiger: 4090, at end: 4090 }
